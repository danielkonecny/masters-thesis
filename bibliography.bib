% Assignment literature

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016},
    isbn = 0262035618,
    edition = 1
}

@book{TensorFlow,
    author = {Ramsundar, Bharath and Zadeh, Reza Bosagh},
    title = {TensorFlow for Deep Learning: From Linear Regression to Reinforcement Learning},
    year = {2018},
    isbn = {1491980451},
    publisher = {O'Reilly Media, Inc.},
    edition = {1},
    abstract = {Learn how to solve challenging machine learning problems with TensorFlow, Googles revolutionary new software library for deep learning. If you have some background in basic linear algebra and calculus, this practical book introduces machine-learning fundamentals by showing you how to design systems capable of detecting objects in images, understanding text, analyzing video, and predicting the properties of potential medicines. TensorFlow for Deep Learning teaches concepts through practical examples and helps you build knowledge of deep learning foundations from the ground up. Its ideal for practicing developers with experience designing software systems, and useful for scientists and other professionals familiar with scripting but not necessarily with designing learning algorithms. Learn TensorFlow fundamentals, including how to perform basic computation Build simple learning systems to understand their mathematical foundations Dive into fully connected deep networks used in thousands of applications Turn prototypes into high-quality models with hyperparameter optimization Process images with convolutional neural networks Handle natural language datasets with recurrent neural networks Use reinforcement learning to solve games such as tic-tac-toe Train deep networks with hardware including GPUs and tensor processing units}
}

@book{LearningOpenCV,
    author = {Bradski, Gary and Kaehler, Adrian},
    title = {Learning OpenCV: Computer Vision in C++ with the OpenCV Library},
    year = {2013},
    isbn = {1449314651},
    publisher = {O'Reilly Media, Inc.},
    edition = {2},
    abstract = {Learning OpenCV puts you in the middle of the rapidly expanding field of computer vision. Written by the creators of the free open source OpenCV library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to "see" and make decisions based on that data.The second edition is updated to cover new features and changes in OpenCV 2.0, especially the C++ interface.Computer vision is everywherein security systems, manufacturing inspection systems, medical image analysis, Unmanned Aerial Vehicles, and more. OpenCV provides an easy-to-use computer vision framework and a comprehensive library with more than 500 functions that can run vision code in real time. Whether you want to build simple or sophisticated vision applications, Learning OpenCV is the book any developer or hobbyist needs to get started, with the help of hands-on exercises in each chapter.This book includes:A thorough introduction to OpenCV Getting input from cameras Transforming images Segmenting images and shape matching Pattern recognition, including face detection Tracking and motion in 2 and 3 dimensions 3D reconstruction from stereo vision Machine learning algorithms }
}

@book{ComputerVision,
    author = {Szeliski, Richard},
    title = {Computer Vision: Algorithms and Applications},
    year = {2010},
    isbn = {1848829345},
    publisher = {Springer-Verlag},
    address = {Berlin, Heidelberg},
    edition = {1},
    abstract = {Humans perceive the three-dimensional structure of the world with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem and what is the current state of the art? Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging, and for fun, consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos. More than just a source of recipes, this exceptionally authoritative and comprehensive textbook/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting them to produce descriptions of a scene. These problems are also analyzed using statistical models and solved using rigorous engineering techniques Topics and features: structured to support active curricula and project-oriented courses, with tips in the Introduction for using the book in a variety of customized courses; presents exercises at the end of each chapter with a heavy emphasis on testing algorithms and containing numerous suggestions for small mid-term projects; provides additional material and more detailed mathematical topics in the Appendices, which cover linear algebra, numerical techniques, and Bayesian estimation theory; suggests additional reading at the end of each chapter, including the latest research in each sub-field, in addition to a full Bibliography at the end of the book; supplies supplementary course material for students at the associated website, http://szeliski.org/Book/. Suitable for an upper-level undergraduate or graduate-level course in computer science or engineering, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries. Its design and exposition also make it eminently suitable as a unique reference to the fundamental techniques and current research literature in computer vision.}
}

@misc{grill2020bootstrap,
    title={Bootstrap your own latent: A new approach to self-supervised Learning}, 
    author={Jean-Bastien Grill and Florian Strub and Florent Altché and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and Rémi Munos and Michal Valko},
    year={2020},
    eprint={2006.07733},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2006.07733},
}

@misc{caron2021emerging,
    title={Emerging Properties in Self-Supervised Vision Transformers}, 
    author={Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
    year={2021},
    eprint={2104.14294},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2104.14294}
}

% Time-Contrastive Networks
@article{sermanet2018timecontrastive,
    author    = {Pierre Sermanet and
               Corey Lynch and
               Jasmine Hsu and
               Sergey Levine},
    title     = {Time-Contrastive Networks: Self-Supervised Learning from Multi-View
               Observation},
    journal   = {CoRR},
    volume    = {abs/1704.06888},
    year      = {2017},
    url       = {http://arxiv.org/abs/1704.06888},
    eprinttype = {arXiv},
    eprint    = {1704.06888},
    timestamp = {Mon, 13 Aug 2018 16:48:58 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/SermanetLHL17.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{asano2020selflabelling,
    title={Self-labelling via simultaneous clustering and representation learning}, 
    author={Yuki Markus Asano and Christian Rupprecht and Andrea Vedaldi},
    year={2020},
    eprint={1911.05371},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/1911.05371}
}

@misc{jing2019selfsupervised,
    title={Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey}, 
    author={Longlong Jing and Yingli Tian},
    year={2019},
    eprint={1902.06162},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/1902.06162}
}

% Additional literature

@book{pml1Book,
    author = "Kevin P. Murphy",
    title = "Probabilistic Machine Learning: An introduction",
    publisher = "MIT Press",
    year = 2022,
    url = {https://probml.github.io/pml-book/book1.html},
    isbn = 0262046822,
    edition = 1,
}
%url = "probml.ai",

@misc{kingma2017adam,
    title={Adam: A Method for Stochastic Optimization}, 
    author={Diederik P. Kingma and Jimmy Ba},
    year={2017},
    eprint={1412.6980},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1412.6980}
}

@misc{dumoulin2016guide,
    title       = {A guide to convolution arithmetic for deep learning},
    author      = {Vincent Dumoulin and Francesco Visin},
    year        = {2016},
    eprint      = {1603.07285},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML},
    url         = {https://arxiv.org/abs/1603.07285}
}

@misc{szegedy2014going,
    title={Going Deeper with Convolutions}, 
    author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
    year={2014},
    eprint={1409.4842},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/1409.4842}
}

% ResNet
@misc{he2015deep-resnet,
    title={Deep Residual Learning for Image Recognition}, 
    author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    year={2015},
    eprint={1512.03385},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/1512.03385}
}

@INPROCEEDINGS{mobilenetv2, 
    author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
    booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    title={MobileNetV2: Inverted Residuals and Linear Bottlenecks},
    year={2018},
    volume={},
    number={},
    pages={4510-4520},
    doi={10.1109/CVPR.2018.00474}
}

@inproceedings{imagenet_cvpr09,
    AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
    TITLE = {ImageNet: A Large-Scale Hierarchical Image Database},
    booktitle={2009 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    YEAR = {2009},
    BIBSOURCE = {http://www.image-net.org/papers/imagenet_cvpr09.bib}
}

@misc{verma2020yoga,
    title={Yoga-82: A New Dataset for Fine-grained Classification of Human Poses},
    author={Verma, Manisha and Kumawat, Sudhakar and Nakashima, Yuta and Raman, Shanmuganathan},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
    pages={4472-4479},
    year={2020},
    url={https://arxiv.org/abs/2004.10362}
}

@InProceedings{yoga-posture-recognition,
    author="Chen, Hua-Tsung
    and He, Yu-Zhen
    and Hsu, Chun-Chieh
    and Chou, Chien-Li
    and Lee, Suh-Yin
    and Lin, Bao-Shuh P.",
    editor="Gurrin, Cathal
    and Hopfgartner, Frank
    and Hurst, Wolfgang
    and Johansen, H{\aa}vard
    and Lee, Hyowon
    and O'Connor, Noel",
    title="Yoga Posture Recognition for Self-training",
    booktitle="MultiMedia Modeling",
    year="2014",
    publisher="Springer International Publishing",
    address="Cham",
    pages="496--505",
    abstract="Self-training plays an important role in sports exercise, but improper training postures can cause serious harm to muscles and ligaments of the body. Hence, more and more researchers are devoted into the development of computer-assisted self-training systems for sports exercise. In this paper, we propose a Yoga posture recognition system, which is capable of recognizing what Yoga posture the practitioner is performing, and then retrieving Yoga training information from Internet to remind his/her attention to the posture. First, a Kinect is used for capturing the user body map and extracting the body contour. Then, star skeleton, which is a fast skeletonization technique by connecting from centroid of target object to contour extremes, is used as a representative descriptor of human posture for Yoga posture recognition. Finally, some Yoga training information for the recognized posture can be retrieved from Internet to remind the practitioner what to pay attention to when practicing the posture.",
    isbn="978-3-319-04114-8"
}

% Triplet Loss
@INPROCEEDINGS{facenet-triplet-loss,
    author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
    booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    title={FaceNet: A unified embedding for face recognition and clustering}, 
    year={2015},
    volume={},
    number={},
    pages={815-823},
    url={http://dx.doi.org/10.1109/CVPR.2015.7298682},
    doi={10.1109/CVPR.2015.7298682},
    ISSN={1063-6919},
    organization={Google Inc.}
}

% Lifted Structure Loss
@INPROCEEDINGS{lifted-structure,
    author={Song, Hyun Oh and Xiang, Yu and Jegelka, Stefanie and Savarese, Silvio},
    booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    title={Deep Metric Learning via Lifted Structured Feature Embedding}, 
    year={2016},
    volume={},
    number={},
    pages={4004-4012},
    doi={10.1109/CVPR.2016.434},
    url={https://ieeexplore.ieee.org/document/7780803}
}

% Multi-Class N-Pair Loss
@inproceedings{multiclass-NIPS2016_6b180037,
    author = {Sohn, Kihyuk},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Improved Deep Metric Learning with Multi-class N-pair Loss Objective},
    url = {https://proceedings.neurips.cc/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf},
    volume = {29},
    year = {2016}
}

% Angular Loss
@INPROCEEDINGS{angular-loss,
    author={Wang, Jian and Zhou, Feng and Wen, Shilei and Liu, Xiao and Lin, Yuanqing},
    booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
    title={Deep Metric Learning with Angular Loss}, 
    year={2017},
    volume={},
    number={},
    pages={2612-2620},
    doi={10.1109/ICCV.2017.283},
    url={https://ieeexplore.ieee.org/document/8237545}
}

% Optical Flow
@article{HORN1981185,
    title = {Determining optical flow},
    journal = {Artificial Intelligence},
    volume = {17},
    number = {1},
    pages = {185-203},
    year = {1981},
    issn = {0004-3702},
    doi = {https://doi.org/10.1016/0004-3702(81)90024-2},
    url = {https://www.sciencedirect.com/science/article/pii/0004370281900242},
    author = {Berthold K.P. Horn and Brian G. Schunck},
    abstract = {Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantized rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image.}
}

% Shi-Tomasi Corner Detector
@INPROCEEDINGS{shi-tomasi-323794,
    author={Jianbo Shi and Tomasi},
    booktitle={1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition}, 
    title={Good features to track}, 
    year={1994},
    volume={},
    number={},
    pages={593-600},
    doi={10.1109/CVPR.1994.323794},
    url={https://ieeexplore.ieee.org/document/323794}
}

% SNE
@inproceedings{sne-NIPS2002_6150ccc6,
    title = {Stochastic Neighbor Embedding},
    author = {Hinton, Geoffrey E and Roweis, Sam},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {S. Becker and S. Thrun and K. Obermayer},
    pages = {},
    publisher = {MIT Press},
    url = {https://proceedings.neurips.cc/paper/2002/file/6150ccc6069bea6b5716254057a194ef-Paper.pdf},
    volume = {15},
    isbn = {0-262-02550-7},
    year = {2003}
}

% t-SNE
@article{tsne-vandermaaten08a,
    author  = {Laurens van der Maaten and Geoffrey Hinton},
    title   = {Visualizing Data using t-SNE},
    journal = {Journal of Machine Learning Research},
    year    = {2008},
    volume  = {9},
    number  = {86},
    pages   = {2579-2605},
    edition = {1},
    url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}
